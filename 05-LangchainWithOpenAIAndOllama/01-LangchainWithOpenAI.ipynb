{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPEN_API_KEY'] = os.getenv('OPEN_API_KEY')\n",
    "\n",
    "## Langsmith Tracking\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o\") ## Here llm is the instance of the model.\n",
    "print(llm) ## Here we are just printing the model instance to verify that the model is loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is Langchain?\") ## Here we are passing a simple input to the model to get the response.\n",
    "print(result) ## Here we are printing the response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9324b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chatprompt template : It is like how you want your llm model to behave or what kind of response you want from the model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt =ChatPromptTemplate.from_messages(  [ (\"system\",\"You are an expert AI engineer.Provide detailed answers to the questions asked by the user.\"),\n",
    "    (\"user\",\"{input}\")] ) ## Here we are creating a chat prompt template with system and user messages.\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb76c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Chain : It is a combination of prompt template and llm model\n",
    "chain=prompt|llm  ## Here we are creating a chain by combining the prompt template and the llm model.\n",
    "response=chain.invoke(\"input: Explain Langchain in detail.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd04527",
   "metadata": {},
   "outputs": [],
   "source": [
    "## strout parser: It is used to structure the output in a particular format like json, list ,dict etc.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser() ## Here we are creating an output parser instance to structure the output in string format.\n",
    "chain=prompt|llm|output_parser ## Here we are creating a chain by combining the prompt template , llm model and output parser.\n",
    "response=chain.invoke(\"input: List down the programming languages used in Langchain.\") ## Here we are passing a input to the chain to get the response.\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
