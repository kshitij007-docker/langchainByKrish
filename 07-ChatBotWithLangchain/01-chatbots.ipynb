{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441615d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1430bf4d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1433442f0>, model_name='meta-llama/llama-guard-4-12b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model=ChatGroq(model=\"meta-llama/llama-guard-4-12b\",groq_api_key=groq_api_key)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba63520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='safe', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 207, 'total_tokens': 209, 'completion_time': 0.00614452, 'prompt_time': 0.022445251, 'queue_time': 0.416895547, 'total_time': 0.028589771}, 'model_name': 'meta-llama/llama-guard-4-12b', 'system_fingerprint': 'fp_2e6f0f978e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ec7d9d58-6d07-40f3-8f8d-c3cc3f816b9e-0', usage_metadata={'input_tokens': 207, 'output_tokens': 2, 'total_tokens': 209})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hello, I am chief AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='safe', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 221, 'total_tokens': 223, 'completion_time': 0.006145769, 'prompt_time': 0.023333589, 'queue_time': 0.422824461, 'total_time': 0.029479358}, 'model_name': 'meta-llama/llama-guard-4-12b', 'system_fingerprint': 'fp_712a32085d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--299358ef-c450-4ec7-8b68-5621fd594ed2-0', usage_metadata={'input_tokens': 221, 'output_tokens': 2, 'total_tokens': 223})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [HumanMessage(content=\"Hello, I am chief AI engineer\"),\n",
    "              AIMessage(content=\"Hello, welcome aboard!\"),\n",
    "              HumanMessage(content=\"What do I do?\")]) ## This is to create a chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f863761",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Message History.\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory ## ChatMessageHistory will be used to store the chat history\n",
    "from langchain_core.chat_history import BaseChatMessageHistory ## BaseChatMessageHistory is the base class for chat history.It is used to define the type of chat history.For example, we can use it to define the type of chat history as ChatMessageHistory.\n",
    "from langchain_core.runnables import RunnableWithMessageHistory ## RunnableWithMessageHistory is used to create a runnable with message history.It is used to create a runnable that can store the chat history.\n",
    "\n",
    "store={} ## store is a dictionary that will be used to store the chat history for different sessions.Dictionary here in simple words is a key value pair where key is session id and value is chat history.\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory: ## get_session_history is a function that takes session_id as input and returns the chat history for that session_id.\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history) ## with_message_history is a runnable that can store the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bcc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"user_123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f4850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke([HumanMessage(content=\"Hello, I am chief AI engineer\")],config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f0e26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config\n",
    "\n",
    "config1={\"configurable\":{\"session_id\":\"user_124\"}}\n",
    "response1=with_message_history.invoke([HumanMessage(content=\"what is my name\")],config=config1)\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d336c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2=with_message_history.invoke([HumanMessage(content=\"My name is john\")],config=config1)\n",
    "response2.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
